{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whale identification_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX0iReP6BHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-736HNTQVNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.model_selection import KFold\n",
        "from PIL import Image \n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as tvm\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apy_qcmtexsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adSJ-CVNVMkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbB14fFJdMr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir -p ~/.kaggle/\n",
        "! mv kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! mkdir -p /content/competition/humpback-whale-identification\n",
        "% cd /content/competition/humpback-whale-identification\n",
        "\n",
        "!kaggle competitions download -c humpback-whale-identification\n",
        "\n",
        "with zipfile.ZipFile(\"/content/competition/humpback-whale-identification/test.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content/competition/humpback-whale-identification/test\")\n",
        "with zipfile.ZipFile(\"/content/competition/humpback-whale-identification/train.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content/competition/humpback-whale-identification/train\")\n",
        "\n",
        "os.remove(\"test.zip\")\n",
        "os.remove(\"train.zip\")\n",
        "\n",
        "train_csv = pd.read_csv(\"/content/competition/humpback-whale-identification/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1fO19GjA2ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subset_data(num_count = 10,new_whale_count = 100):\n",
        "\n",
        "  count_samples = train_csv.groupby('Id').agg('count')\n",
        "  Id_subset = count_samples[count_samples['Image']>num_count]\n",
        "  Id_subset_list = list(Id_subset.index)\n",
        "  label_list = []\n",
        "\n",
        "  for label in Id_subset_list:\n",
        "    if (label != 'new_whale'):\n",
        "      label_list.append(label)\n",
        "\n",
        "  image_subset = train_csv[train_csv['Id'].isin(label_list)]\n",
        "  image_new_whale = train_csv[train_csv['Id'] == 'new_whale']\n",
        "  #image_new_whale_sample = image_new_whale.sample(n = new_whale_count)\n",
        "  image_new_whale_sample = image_new_whale\n",
        "  image_subset = image_subset.append(image_new_whale_sample)\n",
        "  labels = pd.DataFrame(pd.unique(image_subset['Id']))\n",
        "  labels['label_id'] = labels.index\n",
        "  labels.columns = ['label','label_id']\n",
        "  image_subset = pd.merge(image_subset,labels,left_on='Id',right_on='label',how = 'left')\n",
        "  image_subset = image_subset[['Image','label_id']]\n",
        "  image_subset = image_subset.sample(frac=1)\n",
        "  image_label_list = image_subset.values.tolist()\n",
        "  label_list = labels.values.tolist()\n",
        "  count_labels = len(label_list)\n",
        "  return image_label_list,count_labels,label_list\n",
        "\n",
        "def val_generator(image_label_list,n_splits = 5):\n",
        "  kf = KFold(n_splits=5,random_state = None)\n",
        "  val_0,val_1,val_2,val_3,val_4 = kf.split(image_label_list)\n",
        "  return val_0,val_1,val_2,val_3,val_4\n",
        "\n",
        "## Image transforms\n",
        "\n",
        "height = 256\n",
        "width = 256\n",
        "\n",
        "resize = transforms.Resize((height,width))\n",
        "random_rotation = transforms.RandomRotation((-30,+30))\n",
        "random_crop = transforms.RandomCrop((128,128),pad_if_needed=True)\n",
        "horizontal_flip = transforms.transforms.RandomHorizontalFlip()\n",
        "gray_scale = transforms.RandomGrayscale(p=0.5)\n",
        "perspective = transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)\n",
        "noise = transforms.Compose([transforms.Lambda(lambda x : x + torch.randn_like(x))])\n",
        "\n",
        "#normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "tensor_transform = transforms.ToTensor()\n",
        "\n",
        "def train_image_transform(image):\n",
        "\n",
        "  image = resize(image)\n",
        "  #image = normalize(image)\n",
        "  #image = horizontal_flip(image)\n",
        "  image = gray_scale(image)\n",
        "  image = perspective(image)\n",
        "  if random.random() < 0.5:\n",
        "    image = random_rotation(image)\n",
        "  #image = random_crop(image)\n",
        "  image = np.array(image)\n",
        "  image = torch.tensor(image).float()\n",
        "  image = image.permute(2,0,1)\n",
        "  if random.random() < 0.5:\n",
        "    image = noise(image)\n",
        "  return image\n",
        "\n",
        "def test_image_transform(image):\n",
        "\n",
        "  image = resize(image)\n",
        "  #image = normalize(image)\n",
        "  image = np.array(image)\n",
        "  image = torch.tensor(image).float()\n",
        "  image = image.permute(2,0,1)\n",
        "  return image\n",
        "\n",
        "class WhaleTrainDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self,train_list, transform_train = None):\n",
        "    super(WhaleTrainDataset, self).__init__()\n",
        "\n",
        "    self.train_list = train_list\n",
        "    self.no_of_samples = len(self.train_list)\n",
        "    self.transform = transform_train\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    image_name = self.train_list[index][0]\n",
        "    image = Image.open('/content/competition/humpback-whale-identification/train/{}'.format(image_name)).convert('RGB')\n",
        "    label = self.train_list[index][1]\n",
        "    image = self.transform_image(image)\n",
        "\n",
        "    return image,label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.train_list)\n",
        "\n",
        "  def transform_image(self,image):\n",
        "    image = self.transform(image)\n",
        "    return image\n",
        "\n",
        "class WhaleValDataset (data.Dataset):\n",
        "\n",
        "  def __init__(self,val_list,transform_val = None):\n",
        "    super(WhaleValDataset, self).__init__()\n",
        "    self.val_list = val_list\n",
        "    self.no_of_samples = len(self.val_list)\n",
        "    self.transform = transform_val\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    image_name = self.val_list[index][0]\n",
        "    image = Image.open('/content/competition/humpback-whale-identification/train/{}'.format(image_name)).convert('RGB')\n",
        "    label = self.val_list[index][1]\n",
        "    image = self.transform_image(image)\n",
        "    return image,label\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.no_of_samples\n",
        "\n",
        "  def transform_image(self,image):\n",
        "    image = self.transform(image)\n",
        "    return image\n",
        "\n",
        "def train_valid_data_generator (val_fold):\n",
        "\n",
        "  if val_fold == 0:\n",
        "    train_index = val_0[0].tolist()\n",
        "    val_index = val_0[1].tolist()\n",
        "  elif val_fold == 1:\n",
        "    train_index = val_1[0].tolist()\n",
        "    val_index = val_1[1].tolist()\n",
        "  elif val_fold == 2:\n",
        "    train_index = val_2[0].tolist()\n",
        "    val_index = val_2[1].tolist()\n",
        "  elif val_fold == 3:\n",
        "    train_index = val_3[0].tolist()\n",
        "    val_index = val_3[1].tolist()\n",
        "  elif val_fold == 4:\n",
        "    train_index = val_4[0].tolist()\n",
        "    val_index = val_4[1].tolist()\n",
        "\n",
        "  train_list = [image_label_list[i] for i in train_index]\n",
        "  val_list = [image_label_list[i] for i in val_index]\n",
        "\n",
        "  return train_list,val_list\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def load_pretrain(self, pretrain_file):\n",
        "\n",
        "    pretrain_state_dict = torch.load(pretrain_file)\n",
        "    state_dict = self.state_dict()\n",
        "    keys = list(state_dict.keys())\n",
        "    for key in keys:\n",
        "      state_dict[key] = pretrain_state_dict[r'module.'+key]\n",
        "      print(key)\n",
        "    self.load_state_dict(state_dict)\n",
        "    print('')\n",
        "\n",
        "  def __init__(self,num_classes):\n",
        "\n",
        "    super(Net,self).__init__()\n",
        "\n",
        "    self.basemodel = tvm.resnet101(pretrained=True)\n",
        "    self.basemodel.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.basemodel.last_layer = nn.Sequential()\n",
        "    self.basemodel.layer0 = nn.Sequential(self.basemodel.conv1,\n",
        "                                          self.basemodel.bn1,\n",
        "                                          self.basemodel.relu,\n",
        "                                          self.basemodel.maxpool) \n",
        "\n",
        "    self.fea_bn = nn.BatchNorm1d(2048)\n",
        "    self.fc = nn.Linear(2048,num_classes)\n",
        "    self.fea_bn.bias.requires_grad_(False)\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.basemodel.layer0(x)\n",
        "    x = self.basemodel.layer1(x)\n",
        "    x = self.basemodel.layer2(x)\n",
        "    x = self.basemodel.layer3(x)\n",
        "    x = self.basemodel.layer4(x)\n",
        "\n",
        "    x = self.basemodel.avgpool(x)\n",
        "    fea = x.view(x.size(0),-1)\n",
        "    fea = self.fea_bn(fea)\n",
        "\n",
        "    output = (self.fc(fea))\n",
        "    return output\n",
        "\n",
        "def train_model(model,criterion,optimizer,scheduler,num_epochs):\n",
        "\n",
        "  since = time.time()\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for i in range(n_splits):\n",
        "      \n",
        "      print('Fold_index: {}'.format(i+1))\n",
        "\n",
        "      train_list,val_list = train_valid_data_generator(val_fold = i)\n",
        "      datasets = {'train':WhaleTrainDataset(train_list,train_image_transform),'val':WhaleValDataset(val_list,test_image_transform)}\n",
        "\n",
        "      for phase in ['train','val']:\n",
        "        if (phase=='train'):\n",
        "          scheduler.step()\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        dataset = datasets[phase]\n",
        "        data_loader = data.DataLoader(dataset = dataset,batch_size=10)\n",
        "\n",
        "        for images_tensor,labels in data_loader:\n",
        "\n",
        "          images_tensor = images_tensor.to(device)\n",
        "          labels = labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          with torch.set_grad_enabled(phase=='train'):\n",
        "            outputs = model(images_tensor)\n",
        "            _,preds = torch.max(outputs,1)\n",
        "            loss = criterion(outputs,labels)\n",
        "\n",
        "            if(phase=='train'):\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "          running_loss += loss.item() * images_tensor.size(0)\n",
        "          running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "        phase_loss = running_loss / len(dataset)\n",
        "        phase_acc = running_corrects.double() / len(dataset)\n",
        "        \n",
        "        model_name = 'model_resnet101_wt.tar'\n",
        "        path = F\"/content/gdrive/My Drive/{model_name}\"\n",
        "        torch.save({\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  }, path)\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, phase_loss, phase_acc))\n",
        "\n",
        "        if phase == 'val' and phase_acc > best_acc:\n",
        "          best_acc = phase_acc\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_sv34MtZUtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_label_list,count_labels,label_list = subset_data(num_count = 0)\n",
        "val_0,val_1,val_2,val_3,val_4 = val_generator(image_label_list,n_splits = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHNiMajqG1Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net(num_classes = count_labels)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr = 0.000001 ,max_lr = 0.01)\n",
        "num_epochs = 10\n",
        "n_splits = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3c_or3Z5LYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = train_model(model,criterion,optimizer_ft,exp_lr_scheduler,num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m21E2TxPvr3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Training the model from the previous stopped epoch\n",
        "\n",
        "model_name = 'model_resnet101_wt.tar'\n",
        "path = F\"/content/gdrive/My Drive/{model_name}\"\n",
        "checkpoint = torch.load(path)\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "model_1 = train_model(model,criterion,optimizer_ft,exp_lr_scheduler,num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}